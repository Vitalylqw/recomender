Курсовой проект по рекомендательным системам
geekbrains
март 2021 года


Дано (папка data):  
retail_train.csv файл с транзакциями 
product.csv  файл с описанием товаров  
hh_demographic.csv  файл с описанием некторых покупателей  

Основной код вынесен в отдедьные файлы (папка src):

metrics.py  функции с собственными метриками  
recommenders.py собственный модуль для работы с рекомендательными системами 

Целевая метрика - precision@5. Порог для уcпешной сдачи проекта precision@5 > 0.27%

В построении одноруровневой модели использовали подходы уменьшения числа популярных товаров до 5 и 10 тысяч, так же пробовал разные поля для взвешивания матрицы UIM. Пробовал делать расчеты без взвешивания, tf_idf и bm52. Для построоения предсказаний использовали подходы own_recommender , item_simular(в том числе включая item уже купленный пользователем), а так же als.
Из таблицы видно, что существенно лучший результат дает item_simular - 0.400269, причем на него практически не влияют ни поля по которым мы взвешиваем, ни тип взвешивания ни количество ограничений топ популярных item.
Второй по значимости метод - als. На него уже сильно вдиет тип взыешивания, поля по которым расчитывается матрица, и в меньшей мере количесвто топ популярных товаров.. Наилучший результат достигнут при использовании : quantity,count - bm25 - als - 10 000 - 0.3476 Обучение одноуровневой модели велось на данных минус 3 недели. Тест посленине три недели.

Для работы с двухуровневой моделью мы берем 50 лучших рекомендаций из двух лучших систем item_simular и als. С лучшими параметрами. Обучаем на данных минус 9 недель. Получаем recall примерно одинаковый.
Далее используя модель бустинга LGBMClassifier и LGBMRanker обучаем на таргете полученом с 3 по 9 неделю с конца. Сверяем результаты на данных последних трех недель.
ПРоверяем несколько вариантов расчетов:
Только uaer_id и item_id + target Далее добавляем коф взвешивания quantity,count - bm25 Дадее долбавляем информацию о товарах и пользователях
Далнее разрабатываем новые фичи
Результат показал, что LGBMRanker работает лучше, чем больше фич, тем выше результат. Максимальное качество полученно - 0.365849. Причем из какой выборки были получены кандидаты (als или item_simular) значения не имеет

Таким образом при исходных данных и схеме валидации, лучший результат показала одноуровневая модель item_simular
djn
  





